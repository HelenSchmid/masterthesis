{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70503387",
   "metadata": {},
   "source": [
    "# Curate training data for promiscuity model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35baeb",
   "metadata": {},
   "source": [
    "Here, I only included the EnzymeCAGE_train.csv but not the EnzymeCAGE_valid.csv. Maybe in the future, I will/should include both?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from EnzymeCAGE\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_CAGE = pd.read_csv('data/EnzymeCAGE_train.csv')\n",
    "df_protein = pd.read_pickle('/home/helen/cec_degrader/generalize/data/protein.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cff0f6",
   "metadata": {},
   "source": [
    "### All promiscuous enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c75d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2124678/1581111919.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['EC number'] = df['UniprotID'].map(ec_mapping)\n",
      "/tmp/ipykernel_2124678/1581111919.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['EC number'] = df['EC number'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n"
     ]
    }
   ],
   "source": [
    "# Positive samples only\n",
    "df = df_CAGE[df_CAGE['Label'] == 1]\n",
    "\n",
    "# Add EC number from protein.pkl if not present \n",
    "ec_mapping = df_protein.groupby('Entry')['EC number'].apply(list).to_dict()\n",
    "df['EC number'] = df['UniprotID'].map(ec_mapping)\n",
    "df['EC number'] = df['EC number'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Filter to (catalytically) promiscuous enzymes (i.e. present more than once in df)\n",
    "filtered_df = df[df['UniprotID'].duplicated(keep=False)]\n",
    "df  = filtered_df.sort_values(by='UniprotID')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Split reaction SMILEs into substrates and products\n",
    "df[['substrates', 'products']] = df['SMILES'].str.split('>>', expand=True)\n",
    "\n",
    "# Remove H20 and H+ as a substrate\n",
    "def remove_water_and_protons(smiles):\n",
    "    if pd.isna(smiles):\n",
    "        return smiles\n",
    "    parts = smiles.split('.')\n",
    "    parts = [p for p in parts if p not in ('[H]O[H]', '[H+]', '[H]')]\n",
    "    return '.'.join(parts)\n",
    "\n",
    "# Number of substrates and products per entry\n",
    "df['number_substrates'] = df['substrates'].str.count('\\.') + 1\n",
    "df['number_products'] = df['products'].str.count('\\.') + 1\n",
    "\n",
    "#df.to_pickle('data/EnzymeCAGE_train_all_promiscuous.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af591f0e",
   "metadata": {},
   "source": [
    "### Substrate promiscuous enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2124678/3947277988.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_unique = df.groupby('UniprotID', group_keys=False).apply(filter_unique_substrates).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create cannonical substrate strings to detect duplicate substrates \n",
    "def canonical_substrates(substrates):\n",
    "    parts = substrates.split('.')\n",
    "    parts = sorted([p.strip() for p in parts])\n",
    "    return '.'.join(parts)\n",
    "\n",
    "df['substrates_canonical'] = df['substrates'].str.strip().apply(canonical_substrates)\n",
    "\n",
    "# For each UniprotID, remove catalytically promiscuous enzymes by filtering out rows with identical substrates\n",
    "def filter_unique_substrates(group):\n",
    "    counts = group['substrates_canonical'].value_counts()\n",
    "    unique_substrates = counts[counts == 1].index\n",
    "    return group[group['substrates_canonical'].isin(unique_substrates)]\n",
    "\n",
    "df_unique = df.groupby('UniprotID', group_keys=False).apply(filter_unique_substrates).reset_index(drop=True)\n",
    "df_unique = df_unique.drop(columns=['substrates_canonical'])\n",
    "df_unique = df_unique[df_unique['UniprotID'].duplicated(keep=False)]\n",
    "df_unique = df_unique.sort_values(by='UniprotID')\n",
    "\n",
    "# Split substrate SMILES into seperate entries\n",
    "df_unique['substrates_split'] = df_unique['substrates'].str.split('.')\n",
    "df_unique = df_unique.explode('substrates_split').reset_index(drop=True)\n",
    "df_unique.loc[df_unique['number_substrates'] > 1]\n",
    "\n",
    "# For each UniprotID, remove the substrates that are common to all RHEA_IDs within the same UniprotID. The logic being that these do not contribute to promiscuity because stay constant in all reactions. \n",
    "substrate_rhea_counts = df_unique.groupby(['UniprotID', 'substrates_split'])['RHEA_ID'].nunique().reset_index(name='rhea_count')\n",
    "total_rhea_counts = df_unique.groupby('UniprotID')['RHEA_ID'].nunique().reset_index(name='total_rhea_count') # Find the total number of unique RHEA_IDs for each UniprotID\n",
    "merged = pd.merge(substrate_rhea_counts, total_rhea_counts, on='UniprotID')\n",
    "merged['appear_in_all_rhea'] = merged['rhea_count'] == merged['total_rhea_count']\n",
    "substrates_to_remove = merged[merged['appear_in_all_rhea'] == True]\n",
    "\n",
    "df_filtered = df_unique.merge(substrates_to_remove[['UniprotID', 'substrates_split']], \n",
    "                       on=['UniprotID', 'substrates_split'], how='left', indicator=True)\n",
    "\n",
    "df_filtered = df_filtered[df_filtered['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "#df_filtered.to_pickle('data/EnzymeCAGE_train_promiscuous_substrates.pkl')\n",
    "# 132'620 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85247fd8",
   "metadata": {},
   "source": [
    "### Promiscuous esterases (EC 3.1.X.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('data/EnzymeCAGE_train_promiscuous_substrates.pkl')\n",
    "\n",
    "# Filter to only promiscuous esterases\n",
    "uniprot_with_3_1 = df.loc[df['EC number'].fillna('').str.startswith('3.1.'), 'UniprotID'].unique()\n",
    "df_filtered = df[df['UniprotID'].isin(uniprot_with_3_1)].copy()\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "#df_filtered.to_pickle('data/EnzymeCAGE_train_promiscuous_substrates_EC3p1.pkl')\n",
    "\n",
    "# 9'573  entries\n",
    "# Contains all substrate promiscuous enzymes with EC 3.1 having removed catalytically promiscuous enzymes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ccda4",
   "metadata": {},
   "source": [
    "### Thermophilic esterases (EC 3.1.X.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0330d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extremophiles = pd.read_pickle('/home/helen/cec_degrader/generalize/data/extremeophiles.pkl')\n",
    "df  = pd.read_csv('data/EnzymeCAGE_train.csv')\n",
    "df_protein = pd.read_pickle('/home/helen/cec_degrader/generalize/data/protein.pkl')\n",
    "\n",
    "# Positive samples only\n",
    "df = df[df['Label'] == 1]\n",
    "\n",
    "# Add EC number from protein.pkl if not present \n",
    "ec_mapping = df_protein.groupby('Entry')['EC number'].apply(list).to_dict()\n",
    "df['EC number'] = df['UniprotID'].map(ec_mapping)\n",
    "df['EC number'] = df['EC number'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Filter to only extremophilic/thermophilic enzymes\n",
    "df = df[df['UniprotID'].isin(df_extremophiles['Entry'])]\n",
    "\n",
    "# Filter to only esterases (EC 3.1)\n",
    "uniprot_with_3_1 = df.loc[df['EC number'].fillna('').str.startswith('3.1.'), 'UniprotID'].unique()\n",
    "df = df[df['UniprotID'].isin(uniprot_with_3_1)].copy()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Split reaction SMILEs into substrates and products\n",
    "df[['substrates', 'products']] = df['SMILES'].str.split('>>', expand=True)\n",
    "\n",
    "# Remove H20 as a substrate\n",
    "def remove_water(smiles):\n",
    "    if pd.isna(smiles):\n",
    "        return smiles\n",
    "    parts = smiles.split('.')\n",
    "    parts = [p for p in parts if p != '[H]O[H]']\n",
    "    return '.'.join(parts)\n",
    "df['substrates'] = df['substrates'].apply(remove_water)\n",
    "\n",
    "# Number of substrates and products per entry\n",
    "df['number_substrates'] = df['substrates'].str.count('\\.') + 1\n",
    "df['number_products'] = df['products'].str.count('\\.') + 1\n",
    "\n",
    "#df.to_pickle('data/EnzymeCAGE_train_extremophiles_EC3p1.pkl')\n",
    "\n",
    "# 332 entries\n",
    "# Contains all thermophilic esterases irrespective of promiscuity from the enzymeCAGE training data. \n",
    "# This is fewer entries than the number of esterases in the whole extremophiles_df which is 2232! Can we also use all of those???????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
